{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIdT9iu_Z4Rb"
   },
   "source": [
    "# Regresión Básica: Predecir eficiencia de gasolina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHp3M9ZmrIxj"
   },
   "source": [
    "En este notebook, utilizaremos un dataset de coches [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) para construir un modelo de redes neuronales con el que  predecir el consumo de vehículos de 1970 y 1980. En este dataset dispondremos de atributos como Cilindros, desplazamiento, potencia y peso. El objetivo de este ejercicio es predecir las millas por galón de combustible (MPG).\n",
    "\n",
    "El set de datos esta disponible de el siguiente repositorio [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/).\n",
    "\n",
    "\n",
    "Empezaremos importando las librerías principales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1rRo8oNqZ-Rj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFh9ne3FZ-On"
   },
   "source": [
    "### Leyendo los datos\n",
    "\n",
    "En primer lugar, lo que deberemos hacer es descargar el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p9kxxgzvzlyz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\TheBridge\\\\.keras\\\\datasets\\\\auto-mpg.data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\",\n",
    "                                    \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nslsRLh7Zss4"
   },
   "source": [
    "Y lo leemos con pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CiX2FI4gZtTt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Origin  \n",
       "393          82       1  \n",
       "394          82       2  \n",
       "395          82       1  \n",
       "396          82       1  \n",
       "397          82       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MWuJTKEDM-f"
   },
   "source": [
    "### Limpiando los datos\n",
    "\n",
    "Trata los missings y variables categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEJHhN65a2VV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cuym4yvk76vU"
   },
   "source": [
    "### Divide los datos en train y test\n",
    "\n",
    "Ahora divide el dataset en train y test, donde este último sea del 80%.\n",
    "\n",
    "Llama a los datasets ``train_dataset`` y ``test_dataset``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qn-IGhUE7_1H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4ubs136WLNp"
   },
   "source": [
    "### Inspecciona los datos\n",
    "\n",
    "Revisa rápidamente la distribucion conjunta del dataset de entrenamiento mediante un grid de gráficos. Repasa los gráficos de seaborn para ver cuál nos puede ofrecer esta visión, donde la diagonal principal muestre el *kernel density estimate*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRKO_x8gWKv-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gavKO_6DWRMP"
   },
   "source": [
    "Muestra también los estadísticos principales del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi2FzC3T21jR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Db7Auq1yXUvh"
   },
   "source": [
    "### Separa las features del target\n",
    "\n",
    "En este momento, tenemos juntos tanto las variables independientes como el target. Sepáralos para tener ``train_dataset`` y ``test_dataset`` con las variables independientes, y ``train_labels`` y ``test_labels`` como target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2sluJdCW7jN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRklxK5s388r"
   },
   "source": [
    "### Estandariza los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ywmerQ6dSox"
   },
   "source": [
    "Es una buena práctica estandarizar los datasets con variables de diferentes escalas y rangos. Aunque el modelo podría converger sin estandarizar, dificulta el entrenamiento y hace que el modelo resultante dependa de la elección de las unidades utilizadas en la entrada. Estandariza los datos sobreescribiendo los datos ``train_dataset`` y ``test_dataset``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlC5ooJrgjQF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmjdzxKzEu1-"
   },
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SWtkIjhrZwa"
   },
   "source": [
    "### Construye el modelo\n",
    "\n",
    "Construyamos nuestro modelo. Aquí, utilizaremos un modelo `secuencial` con dos capas ocultas densamente conectadas y una capa de salida que devuelva un único valor continuo.\n",
    "\n",
    "Por tanto, necesitamos construir un modelo con tres capas:\n",
    "  * **Entrada**: con activación relu.\n",
    "  * **Hidden layer**: con activación relu\n",
    "  * **Salida**: será de regresión, por lo que se compondrá de una única neurona.\n",
    "  \n",
    "Pon las neuronas que consideres para las dos primeras capas, por ejemplo, 64. Después iteraremos con diferentes combinaciones.\n",
    "\n",
    "Para el compile utiliza un ``loss='mse'``, un ``optimizer = `tf.keras.optimizers.RMSprop(0.001)` ``, y en ``metrics`` utiliza una lista con el `mae` y `mse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c26juK7ZG8j-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj49Og4YGULr"
   },
   "source": [
    "### Inspecciona el modelo\n",
    "\n",
    "Utiliza uno de los métodos que hemos visto para obtener una descripción simple del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReAD0n6MsFK-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-qWCsh6DlyH"
   },
   "source": [
    "### Entrenar el modelo\n",
    "\n",
    "Entrena el modelo para 1000 epochs y guarda los resultados del entrenamiento en una variable llamada `history`.\n",
    "Emplea en el entrenamiento un 20% de los datos para validación, mediante el argumento `validation_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sD7qHCmNIOY0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQm3pc0FYPQB"
   },
   "source": [
    "Visualiza el progreso de entrenamiento del modelo usando las estadísticas almacenadas en el objeto `history.history`, donde representes el error de train con el de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Xj91b-dymEy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6XriGbVPh2t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Alguna conclusión respecto a este gráfico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqsuANc11FYv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añade un early stopping al modelo. Ya hemos visto cómo hacerlo mediante el parámetro ``callback``. En este caso, pon un ``patience`` de 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdMZuhUgzMZ4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3St8-DmrX8P4"
   },
   "source": [
    "Evalúa el rendimiento del modelo mediante el estudio de los 3 valores que te devuelve el método que hemos visto para ello, que son: ``loss``, ``mae`` y ``mse``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jl_yNr5n1kms"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vt6W50qGsJAL"
   },
   "source": [
    "### Prediciendo\n",
    "\n",
    "Ahora, probemos el modelo realizando una predicción de los primeros 10 valores y represéntalos en una gráfica frente a sus valores reales, es decir, uno en cada eje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-OHX4DiXd8x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO: Mejora el modelo\n",
    "\n",
    "Aunque estemos ante muy pocas muestras, y el verdadero poder de las redes neuronales se observa con grandes volúmenes de datos, vamos a tratar de mejorar los resultados.\n",
    "\n",
    "Modifica algunos de los parámetros utilizados en este modelo para intentar mejorar los resultados. Hay muchas posibilidades, pero empieza tocando un parámtro hasta encontrar un valor adecuado y luego modiica otros hasta obtener algo que sea suficientemente bueno.\n",
    "\n",
    "También podrías crear nuevas variables para ver si mejora el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "regression.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
