{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "A la hora de trabajar con redes neuronales tenemos varias opciones. Una de las más utilizadas es TensorFlow, que permite trabajar con las redes a un nivel de detalle excepcional. Sin embargo, esta capacidad tan buena para los más desarrollados matemáticos, resulta un caos para todo usuario medio. Por ello, surgió Keras, una capa de abstracción que nos permite trabajar con redes neuronales sin tener que tener un amplio dominio de las redes neronales, siendo hoy en día la librería más utilizada para tratar este tipo de problemas.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)\n",
    "\n",
    "Para utilizarla, deberemos instalarla. Descomenta las siguientes líneas para hacerlo desde el propio notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicho esto, pasemos a la acción.\n",
    "\n",
    "Empezaremos importando las principales librerías que vamos a utilizar, donde ya podemos ver la aparición de Keras y TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos también los datos de MNIST, que son los datos de imágenes con números escritos a mano. A diferencia de lo que vimos en su día, en este caso tenemos imágenes con más detalle, lo que hará más complicado el problema.\n",
    "\n",
    "En este caso, como estamos empezando, no vamos a tratar imágenes con redes convolucionales (perdemos la estructura espacial 2D), que son extensamente utilizadas en este tipo de problemas y que explicaremos el próximo día. En este caso, vamos a convertir cada imagen en un vecotr de píxeles, donde cada una de ellas se corresponderá con un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos así como el conjunto de train y test:\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos las dimensiones del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y vemos qué pinta tiene una imagen en concreto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En total son 60.000 imágenes de 28x28 pixeles cada una. Ya hemos visto una imagen en forma de array, pero también podemos interpretarla como una imagen en blanco y negro con diferentes intensidades de color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si te fijas bien en los datos anteriores, cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "### EJERCICIO\n",
    "\n",
    "1. ¿Se te ocurre alguna manera de normalizar los datos?\n",
    "\n",
    "Mantén los nombres de X_train, X_test, y_train e y_test para los valores normalizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, a diferencia de lo que hemos visto para otros modelos, necesitamos separar datos para validación. Estos datos se usarán durante el entrenamiento, así que los cogeremos de train.\n",
    "\n",
    "Otra opción sería especificarle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la última (salida) suele ser una softmax.\n",
    "\n",
    "\n",
    "Tenemos diferentes formas de crear nuestro modelo de Deep Learning:\n",
    "\n",
    "\n",
    "#### Forma 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(units=300, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=100, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forma 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(units=300, activation='relu'),\n",
    "    keras.layers.Dense(units=100, activation='relu'),\n",
    "    keras.layers.Dense(units=10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001DD3E7D8E50>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1dd3e7d89a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1dd3e7d8e50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1dd3e7d8f10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1dd3e7d8700>]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 300)\n"
     ]
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03587243, -0.00890587, -0.00376103, ...,  0.07061188,\n",
       "        -0.04048741,  0.0006762 ],\n",
       "       [ 0.03159229, -0.05104004, -0.0307604 , ..., -0.03828533,\n",
       "        -0.00251138,  0.03575596],\n",
       "       [-0.05559868,  0.07049105, -0.02818103, ...,  0.05743156,\n",
       "        -0.05540546, -0.02647238],\n",
       "       ...,\n",
       "       [-0.02049126, -0.07426091,  0.03116566, ...,  0.00838768,\n",
       "        -0.01227435, -0.01734278],\n",
       "       [ 0.06345643, -0.00946987,  0.03797799, ..., -0.05601543,\n",
       "        -0.02027949,  0.06929643],\n",
       "       [-0.0475    ,  0.01128802, -0.06490497, ...,  0.04087995,\n",
       "        -0.03394452, -0.04597621]], dtype=float32)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución mediante el método ``compile``, donde podemos especificar tanto el [optimizador](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) como la [función de coste](https://www.tensorflow.org/api_docs/python/tf/keras/losses).\n",
    "\n",
    "\n",
    "También tenemos más de una forma de hacerlo:\n",
    "\n",
    "\n",
    "#### Forma 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(), # optimizer = 'sgd'\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(), # \"sparse_categorical_crossentropy\"\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forma 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD (descenso de gradiente estocástico, que es una versión con aproximaciones del descenso de gradiente, que permite agilizar cálculos), y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.0835 - accuracy: 0.9752 - val_loss: 0.0947 - val_accuracy: 0.9716\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.9777 - val_loss: 0.0918 - val_accuracy: 0.9725\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9785 - val_loss: 0.0901 - val_accuracy: 0.9728\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9792 - val_loss: 0.0890 - val_accuracy: 0.9734\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0691 - accuracy: 0.9796 - val_loss: 0.0883 - val_accuracy: 0.9734\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0677 - accuracy: 0.9800 - val_loss: 0.0877 - val_accuracy: 0.9736\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0665 - accuracy: 0.9804 - val_loss: 0.0871 - val_accuracy: 0.9741\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0654 - accuracy: 0.9808 - val_loss: 0.0866 - val_accuracy: 0.9738\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.0644 - accuracy: 0.9812 - val_loss: 0.0860 - val_accuracy: 0.9741\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.0635 - accuracy: 0.9814 - val_loss: 0.0858 - val_accuracy: 0.9741\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0626 - accuracy: 0.9818 - val_loss: 0.0853 - val_accuracy: 0.9745\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 0.9818 - val_loss: 0.0849 - val_accuracy: 0.9749\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0610 - accuracy: 0.9822 - val_loss: 0.0846 - val_accuracy: 0.9749\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9825 - val_loss: 0.0843 - val_accuracy: 0.9746\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0596 - accuracy: 0.9826 - val_loss: 0.0839 - val_accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val) # Tb argumento validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1276 - accuracy: 0.9638 - val_loss: 0.1392 - val_accuracy: 0.9639\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1217 - accuracy: 0.9656 - val_loss: 0.1289 - val_accuracy: 0.9638\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1163 - accuracy: 0.9675 - val_loss: 0.1322 - val_accuracy: 0.9644\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1112 - accuracy: 0.9683 - val_loss: 0.1212 - val_accuracy: 0.9669\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1062 - accuracy: 0.9699 - val_loss: 0.1186 - val_accuracy: 0.9677\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1017 - accuracy: 0.9718 - val_loss: 0.1147 - val_accuracy: 0.9690\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0974 - accuracy: 0.9727 - val_loss: 0.1116 - val_accuracy: 0.9702\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.1097 - val_accuracy: 0.9701\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0899 - accuracy: 0.9755 - val_loss: 0.1074 - val_accuracy: 0.9711\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0865 - accuracy: 0.9760 - val_loss: 0.1048 - val_accuracy: 0.9710\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0832 - accuracy: 0.9771 - val_loss: 0.1041 - val_accuracy: 0.9713\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0801 - accuracy: 0.9781 - val_loss: 0.1016 - val_accuracy: 0.9718\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0770 - accuracy: 0.9789 - val_loss: 0.1036 - val_accuracy: 0.9713\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0743 - accuracy: 0.9796 - val_loss: 0.0991 - val_accuracy: 0.9729\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.1003 - val_accuracy: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd3a4d8ca0>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val) # O podemos usar el argumento validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.8826428055763245,\n",
       "  0.3776881694793701,\n",
       "  0.31330159306526184,\n",
       "  0.2782365083694458,\n",
       "  0.25291189551353455,\n",
       "  0.23301959037780762,\n",
       "  0.21629486978054047,\n",
       "  0.20153291523456573,\n",
       "  0.1887216418981552,\n",
       "  0.17743197083473206,\n",
       "  0.16697202622890472,\n",
       "  0.15744571387767792,\n",
       "  0.14925244450569153,\n",
       "  0.1413659006357193,\n",
       "  0.13417300581932068],\n",
       " 'accuracy': [0.789900004863739,\n",
       "  0.8966799974441528,\n",
       "  0.9117000102996826,\n",
       "  0.92194002866745,\n",
       "  0.9283199906349182,\n",
       "  0.9341199994087219,\n",
       "  0.9392399787902832,\n",
       "  0.9430000185966492,\n",
       "  0.9467399716377258,\n",
       "  0.9496399760246277,\n",
       "  0.9526799917221069,\n",
       "  0.9552800059318542,\n",
       "  0.9582399725914001,\n",
       "  0.9597799777984619,\n",
       "  0.9627400040626526],\n",
       " 'val_loss': [0.3997124135494232,\n",
       "  0.30829283595085144,\n",
       "  0.2710588276386261,\n",
       "  0.2526648938655853,\n",
       "  0.22700822353363037,\n",
       "  0.21517077088356018,\n",
       "  0.20106613636016846,\n",
       "  0.1875396966934204,\n",
       "  0.18022193014621735,\n",
       "  0.17031913995742798,\n",
       "  0.16308511793613434,\n",
       "  0.15434876084327698,\n",
       "  0.14800848066806793,\n",
       "  0.14108631014823914,\n",
       "  0.13617312908172607],\n",
       " 'val_accuracy': [0.8974000215530396,\n",
       "  0.9146999716758728,\n",
       "  0.9240999817848206,\n",
       "  0.9284999966621399,\n",
       "  0.9373999834060669,\n",
       "  0.940500020980835,\n",
       "  0.945900022983551,\n",
       "  0.9505000114440918,\n",
       "  0.9523000121116638,\n",
       "  0.9544000029563904,\n",
       "  0.9570000171661377,\n",
       "  0.958299994468689,\n",
       "  0.9599999785423279,\n",
       "  0.9617000222206116,\n",
       "  0.9628000259399414]}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.12764215469360352,\n",
       "  0.12171982228755951,\n",
       "  0.11629904061555862,\n",
       "  0.11117061227560043,\n",
       "  0.10624893754720688,\n",
       "  0.10173448175191879,\n",
       "  0.0974331647157669,\n",
       "  0.09379906207323074,\n",
       "  0.08991340547800064,\n",
       "  0.0864897072315216,\n",
       "  0.08322304487228394,\n",
       "  0.0800652951002121,\n",
       "  0.07696111500263214,\n",
       "  0.07427415251731873,\n",
       "  0.07159693539142609],\n",
       " 'accuracy': [0.9637799859046936,\n",
       "  0.9656000137329102,\n",
       "  0.967519998550415,\n",
       "  0.9682999849319458,\n",
       "  0.9699199795722961,\n",
       "  0.9717599749565125,\n",
       "  0.9726999998092651,\n",
       "  0.9738799929618835,\n",
       "  0.9755200147628784,\n",
       "  0.9759600162506104,\n",
       "  0.9771400094032288,\n",
       "  0.9780799746513367,\n",
       "  0.9788600206375122,\n",
       "  0.9796199798583984,\n",
       "  0.9805999994277954],\n",
       " 'val_loss': [0.139187291264534,\n",
       "  0.12891776859760284,\n",
       "  0.13223783671855927,\n",
       "  0.12117308378219604,\n",
       "  0.11855784803628922,\n",
       "  0.11467713862657547,\n",
       "  0.11161725223064423,\n",
       "  0.10965317487716675,\n",
       "  0.1073906272649765,\n",
       "  0.10477219521999359,\n",
       "  0.10412301123142242,\n",
       "  0.1015951931476593,\n",
       "  0.10362859070301056,\n",
       "  0.099146768450737,\n",
       "  0.10026223957538605],\n",
       " 'val_accuracy': [0.9639000296592712,\n",
       "  0.9638000130653381,\n",
       "  0.9643999934196472,\n",
       "  0.9668999910354614,\n",
       "  0.9677000045776367,\n",
       "  0.968999981880188,\n",
       "  0.9702000021934509,\n",
       "  0.9700999855995178,\n",
       "  0.9710999727249146,\n",
       "  0.9710000157356262,\n",
       "  0.9713000059127808,\n",
       "  0.9718000292778015,\n",
       "  0.9713000059127808,\n",
       "  0.9728999733924866,\n",
       "  0.9725000262260437]}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, podemos actuar para mejorarlo. Podemos cambiar el learning rate y el optimizador. Y después, podemos proceder con las capas, neuronas y funciones de activación. Todas estas combinaciones son poco predecibles a priori, por lo que no tenemos un librillo que nos diga qué hacer en cada caso.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test para ver el real desempeño de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9715\n",
      "test loss, test acc: [0.09557635337114334, 0.9714999794960022]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.002, 0.   , 0.   , 0.   , 0.997, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(\"shape\", predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1302 - val_loss: 0.4598\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4269 - val_loss: 0.4669\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3941 - val_loss: 0.4182\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.4305\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.8961\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.3602\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3534\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.5211\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3196 - val_loss: 0.3439\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3191 - val_loss: 0.4953\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.334 - 1s 1ms/step - loss: 0.3351 - val_loss: 0.3766\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3271 - val_loss: 0.3313\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3237 - val_loss: 0.3287\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3327 - val_loss: 0.3537\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.7576\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.4571\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.3171\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.6557\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.5083\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 1.5501\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd')\n",
    "history = model.fit(X_train,\n",
    "         y_train,\n",
    "         epochs=20,\n",
    "         validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 739us/step - loss: 0.3264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3263915479183197"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1484948 ],\n",
       "       [4.816121  ],\n",
       "       [0.66984713]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1484948 ],\n",
       "       [4.816121  ],\n",
       "       [0.66984713]], dtype=float32)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.906  , 5.00001, 0.621  ])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Sirven para que el modelo se vaya guardando tras cada epoch, así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2955 - val_loss: 0.4348\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.4459\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3079\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2901 - val_loss: 0.4747\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.7055\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.3788\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2872 - val_loss: 2.4755\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 1.0400\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.3004\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2800 - val_loss: 0.3187\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 0.3112\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2769 - val_loss: 0.3076\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2740 - val_loss: 0.6650\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2745 - val_loss: 0.2953\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2720 - val_loss: 0.3030\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.2914\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.2979\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2710 - val_loss: 0.9586\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2710 - val_loss: 0.8605\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2720 - val_loss: 0.3513\n"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                     y_train,\n",
    "                     epochs=20,\n",
    "                     validation_data=(X_valid, y_valid),\n",
    "                     callbacks=[checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un número de epochs llamado `patience`. Se puede combinar con el callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.2847\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2596 - val_loss: 4.4693\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2618 - val_loss: 1.4136\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2711 - val_loss: 0.3648\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2593 - val_loss: 0.2851\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2594 - val_loss: 1.9134\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience=5,\n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                     y_train,\n",
    "                     epochs=20,\n",
    "                     validation_data=(X_valid, y_valid),\n",
    "                     callbacks=[checkpoint, early_stopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo elijo los parámetros para inicializar el modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una pregunta muy repetida entre los que empiezan con los modelos de Machine Learning, y es una pregunta muy acertada.\n",
    "\n",
    "Sin embargo, tal como hemos visto en muchas de las acciones pasadas, no tenemos una fórmula mágica que nos ayude a definir los parámetros concretos con los que mejor funcionará nuestro algoritmo. En cambio, sí que tenemos ciertas pautas que seguir.\n",
    "\n",
    "1. Asegúrate de que necesitas usar una red neuronal, ya que quizás tu problema se pueda resolver con otros modelos menos costoss computacionalmente o que nor equieran tantos datos para aprender y ofrecer buenos resultados.\n",
    "2. Empieza de menos a más, siempre comprobando los resultados que obtienes.\n",
    "    * Si ves que obtienes mucho error en train, habrá que añadir capas o neuronas a las capas que tienes, cambiar los learning_rates...\n",
    "    * Si ves que en test tienes mucho error en comparación con train, significa que estás sobreentrenando, por lo que tendrás que reducir capas, neuronas o epochs\n",
    "3. Cuantas más epochs, más probabilidad de overfitting, por lo que tendremos que tener cuidado, para lo que podemos utilizar el early stopping\n",
    "4. En cuanto al batch_size, cuanto más grande sea mayor será la estabilidad del modelo, además de ir más rápido. Pero puede que debido a eso no aprenda como es debido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
