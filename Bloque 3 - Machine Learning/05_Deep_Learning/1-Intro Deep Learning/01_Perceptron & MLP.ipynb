{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron\n",
    "\n",
    "<img src=\"./img/perceptron-6168423.jpg\" alt=\"drawing\" width=\"650\"/>\n",
    "\n",
    "Empezamos cargando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos datos. Utilizaremos el dataset de pinguinos de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "      <th>sex_FEMALE</th>\n",
       "      <th>sex_MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0        0            39.1           18.7              181.0       3750.0   \n",
       "1        0            39.5           17.4              186.0       3800.0   \n",
       "2        0            40.3           18.0              195.0       3250.0   \n",
       "4        0            36.7           19.3              193.0       3450.0   \n",
       "5        0            39.3           20.6              190.0       3650.0   \n",
       "\n",
       "   island_Biscoe  island_Dream  island_Torgersen  sex_FEMALE  sex_MALE  \n",
       "0              0             0                 1           0         1  \n",
       "1              0             0                 1           1         0  \n",
       "2              0             0                 1           1         0  \n",
       "4              0             0                 1           1         0  \n",
       "5              0             0                 1           0         1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# Limpiamos un poco los datos\n",
    "df.dropna(inplace=True)\n",
    "cleanup_nums = {\"species\": {\"Adelie\": 0,\n",
    "                            \"Chinstrap\": 1,\n",
    "                            \"Gentoo\": 2},\n",
    "               \"sex\": {\"Male\": 0,\n",
    "                       \"Female\": 1}}\n",
    "df.replace(cleanup_nums, inplace=True)\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 9)\n",
      "(67, 9)\n",
      "(266,)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar un Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34328358208955223"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X_train, y_train)\n",
    "per_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850746268656716"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos a estandarizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_s = sc.transform(X_train)\n",
    "X_test_s = sc.transform(X_test)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X_train_s, y_train)\n",
    "per_clf.score(X_test_s, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_s, y_train)\n",
    "log_reg.score(X_test_s, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, en ambos modelos, parece que la estandarización es la clave, y es que ambos modelos son muy dependientes de las escalas de los datos.\n",
    "\n",
    "Aun así, si nos fijamos en el comportamiento base del perceptrón, parece que no es muy bueno (pese a que con ayuda del StandardScaler mejora mucho). Y eso que estamos hablando de un modelo muy sencillito. Por lo tanto, parece razonable estudiar configuraciones más complejas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5676691729323309\n",
      "0.5373134328358209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter = 500)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(mlp.score(X_train, y_train))\n",
    "print(mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos otra configuración. Es posible crear una red neuronal desde la propia función de MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6766917293233082\n",
      "0.6716417910447762\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter = 500,\n",
    "                   activation='tanh',\n",
    "                   hidden_layer_sizes = (150, 150, 150))\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(mlp.score(X_train, y_train))\n",
    "print(mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno, parece que nuestra red de perceptrones mejora mucho el perceptrón por sí solo, pero seguimos obteniendo algo que dista mucho de lo que queremos. Y es que, al igual que acabamos de ver para el perceptrón, las redes multicapa de perceptrones utilizan descenso del gradiente, y por tanto son muy sensibles al escalado.\n",
    "\n",
    "Estandarizamos para el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_s = sc.transform(X_train)\n",
    "X_test_s = sc.transform(X_test)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X_train_s, y_train)\n",
    "print(per_clf.score(X_train_s, y_train))\n",
    "print(per_clf.score(X_test_s, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_s, y_train)\n",
    "print(log_reg.score(X_train_s, y_train))\n",
    "print(log_reg.score(X_test_s, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scal =scaler.transform(X_train)\n",
    "X_test_scal =scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "mlp.fit(X_train_scal, y_train)\n",
    "print(mlp.score(X_train_scal, y_train))\n",
    "print(mlp.score(X_test_scal, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidentemente, como estamos con unos datos muy preparados para este ejemplo, al estandarizar nos ofrecen un resultado perfecto, como podíamos esperar tras ver el ejemplo anterior.\n",
    "\n",
    "De este modo, se pone de manifiesto la importancia del escalado en este tipo de problemas, ya que son muy dependientes de las relaciones entre variables. Por ello, será muy importante trabajar con el StandardScaler cuando hablemos de modelos lineales, ya que tanto el ``Perceptrón``, como la ``Regresión Logística`` o la configuración ``MLP`` consiguen un resultado muy bueno tras su aplicación.\n",
    "\n",
    "Pero bueno, realmente no hemos visto nada que nos mejore una barbaridad, así que hagamos un ejercicio donde pongamos las cosas (un poquito) más difíciles a nuestro modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, vamos a ver cómo se comportan nuestros modelos con la clasificación de medicamentos. Para ello, leeremos un dataset con algunas columnas categóricas, que deberemos convertir a numéricas de la forma que creamos conveniente.\n",
    "\n",
    "Utiliza un reparto train/test de 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../drug200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
